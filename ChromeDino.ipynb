{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9873a6-604d-4818-938b-f9bc0aacec4c",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d3ddb-9d07-4832-a6c0-7124aa7949e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c5eb4-0dcf-4d5d-b85f-e5243421ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable hinterland/hinterland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0799473-54f3-4aec-8c95-39d4c78d73b5",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0015039-75b3-4f7f-b467-1198e7dc8bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra] protobuf==3.20.*\n",
    "# Protobuf is efficient for serializing and deserializing complex data structures, \n",
    "# which is beneficial for machine learning models and their configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf093931-2f7b-4c37-bfcd-1098dce1e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/PyDirectInput/ will be used to send key input \n",
    "# https://pypi.org/project/pytesseract/ will be used to read characters from game\n",
    "## tesseract needs https://github.com/UB-Mannheim/tesseract/wiki - \n",
    "## mss for screen capture - faster than opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd12c0-2dac-4f28-bee6-3d9a1a061871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pytesseract mss pydirectinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73889e6b-a662-4a9f-926a-8307c1a4c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mss for screen cap\n",
    "from mss import mss\n",
    "# Sending commands \n",
    "import pydirectinput\n",
    "# OpenCV allows us to frame processing\n",
    "import cv2\n",
    "# Transformational framework\n",
    "import numpy as np\n",
    "# For OCR \"GAME OVER\" extraction\n",
    "import pytesseract\n",
    "# Visualize captured frames\n",
    "from matplotlib import pyplot as plt\n",
    "# For pauses - between when we send commands vs get back frames\n",
    "import time\n",
    "# Environment components - Box is shape of game input, Discrete is shape of action\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2df755-a5fd-490b-8dc8-6d0623eb6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df39aeb8-47d1-4885-8607-971e2a860a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4.0.20240606\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "print(pytesseract.get_tesseract_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1bd0d-daaf-483b-b6ed-e55ca3b19fd5",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b923bc-955f-4a0d-bcf4-033e4b352fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(Env):\n",
    "    # Setup the environment action and observation shape\n",
    "    def __init__(self):\n",
    "        # Subclass model - uses to use the base class\n",
    "        super().__init__()\n",
    "        # Setup the environment\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1, 83,100), dtype=np.uint8)\n",
    "        # Action key - 0 = Spacebar, 1 = Duck(down) 2 = No action(no op)\n",
    "        self.action_space = Discrete(2)\n",
    "        # Define extraction parameters for the game\n",
    "        # https://python-mss.readthedocs.io/api.html?highlight=grab#mss.base.MSSBase.grab\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top':300, 'left':0, 'width':600, 'height':500}\n",
    "        self.done_location = {'top':400, 'left':500, 'width':900, 'height':140}\n",
    "        \n",
    "    # What is called to do something in the game, typically we get back next game frame, reward, done, other info\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0:'space',\n",
    "            1:'no_op'\n",
    "        }\n",
    "        if action != 2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        # Checking if the game is done\n",
    "        done, done_cap = self.get_done()\n",
    "        # Get the next observation\n",
    "        new_observation = self.get_observation()\n",
    "        # Reward - we get a point for every frame that we are alive\n",
    "        reward = 1\n",
    "        # Info dictionary\n",
    "        info = {}\n",
    "\n",
    "        return new_observation, reward, done, info\n",
    "\n",
    "    # Visualize the game\n",
    "    def render(self):\n",
    "        cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "        \n",
    "    # Restart the game\n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=50, y=50)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation()\n",
    "        \n",
    "    # Get the part of the observation of the game\n",
    "    def get_observation(self):\n",
    "        # Get the screen capture of game\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        # Grayscaling\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize\n",
    "        resized = cv2.resize(gray, (100, 83))\n",
    "        # Add channels first\n",
    "        channel = np.reshape(resized, (1, 83, 100))\n",
    "        \n",
    "        return channel\n",
    "    # Checks if \"game over\" is displayed in game\n",
    "    def get_done(self):\n",
    "        # Get done screen\n",
    "        done_cap = np.array(self.cap.grab(self.done_location))[:,:,:3]\n",
    "        # Valid done text\n",
    "        done_strings = [\"GAME\", \"chro\", \"GAHE\"]\n",
    "        \n",
    "        # Apply OCR\n",
    "        done = False\n",
    "        res = pytesseract.image_to_string(done_cap)[:4]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "        \n",
    "        return done, done_cap\n",
    "    # This closes the observation\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07d728-0638-4bf9-99c7-58c37c5dfdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d8c47-f708-4a0e-a794-b1a7d567180b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "done, done_cap = env.get_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06921333-7641-4824-900c-69f7fb2a444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f329e6a-d0ea-4c55-80a9-16da3ff690b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92426a9-4b2c-4747-b424-7a8d61e87f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.image_to_string(done_cap)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219f812-072b-4389-bdf4-8d3fecee614c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.array(env.get_done()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba69b0-5548-4ec9-965e-32996a998950",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37568e12-c258-45e9-ad41-53a2d6fbcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(env.get_observation()[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337ac9b-f2d0-4846-aa01-61a12769c607",
   "metadata": {},
   "source": [
    "## 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05135976-e182-4210-9421-0f5483893203",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f715e2-9c3e-4bff-9838-2f9a5cac2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c86f1-2ff1-4fb2-a03f-e1a480aca9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c3498-f600-4f83-b3e0-bcef1d75ff2e",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dad61d-67b8-4143-b920-0533c62bde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play 10 games\n",
    "for episode in range(1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "    print(f'Total Reward for espisode {episode} is {total_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ee9c8-acdf-494a-8804-d8203418b346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9172454e-50b3-4602-ba75-8798758d8d54",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da716ed-f8fc-40a9-be03-61d6f4120f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file navigation\n",
    "import os\n",
    "# Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Impor the sb3 environment checker\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3668c55-3bd7-4b87-b4ff-97c9d0e5e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f3b3d-6ea9-4dd5-be2b-740453c0d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb7ff61-00c2-4313-83a7-3df58fafe233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainingLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c91a1b5f-2cb2-40c1-baf9-eaa17a2eede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/ChromeDino'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f171908-81e8-4dc2-923b-47feaff2700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainingLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e64f7-5096-4e63-b2a9-814ca8a62fa2",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1674448-8517-4400-ae7b-6bcbf4dad3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DQN algo\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9513a408-3cbc-4331-8a60-ddc99851fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Create the DQN model\n",
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1,\n",
    "            buffer_size=200_000, learning_starts=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c853d436-00a0-47a5-b5b4-35f172766dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/ChromeDino\\DQN_4\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.5      |\n",
      "|    ep_rew_mean      | 9.5      |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1        |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 38       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "FailSafeException",
     "evalue": "PyDirectInput fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pydirectinput.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailSafeException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:269\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    262\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:311\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    308\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 311\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:543\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    540\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    542\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    546\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:163\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:60\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m---> 60\u001b[0m         obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:84\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m, in \u001b[0;36mWebGame.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     44\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mpydirectinput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     pydirectinput\u001b[38;5;241m.\u001b[39mpress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_observation()\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\pydirectinput\\__init__.py:241\u001b[0m, in \u001b[0;36m_genericPyDirectInputChecks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrappedFunction)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    239\u001b[0m     funcArgs \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetcallargs(wrappedFunction, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 241\u001b[0m     \u001b[43mfailSafeCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     returnVal \u001b[38;5;241m=\u001b[39m wrappedFunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    243\u001b[0m     _handlePause(funcArgs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pause\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mD:\\!Python Applications\\RIFL\\new_env_py38\\lib\\site-packages\\pydirectinput\\__init__.py:223\u001b[0m, in \u001b[0;36mfailSafeCheck\u001b[1;34m()\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfailSafeCheck\u001b[39m():\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m FAILSAFE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(position()) \u001b[38;5;129;01min\u001b[39;00m FAILSAFE_POINTS:\n\u001b[1;32m--> 223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FailSafeException(\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyDirectInput fail-safe triggered from mouse moving to a corner of the screen. To disable this \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail-safe, set pydirectinput.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m         )\n",
      "\u001b[1;31mFailSafeException\u001b[0m: PyDirectInput fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pydirectinput.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.learn(total_timesteps=5000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53434de-a9db-46d8-b153-5017d11acaba",
   "metadata": {},
   "source": [
    "# 4. Test out the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06da320-2636-49a4-8c07-196b7d69f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(os.path.join(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316343ca-c48d-4981-9c29-12ab38c1de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play 10 games\n",
    "for episode in range(10):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        total_reward += reward\n",
    "    print(f'episode reward for {episode} is {total_reward}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c7809-3e93-4d9a-a276-40a2d4d30da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd24cbd-82a2-4061-874a-4f6048ae7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d8b0b-0db2-48d4-9405-9fccfaee6206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (new_env_py38)",
   "language": "python",
   "name": "new_env_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
